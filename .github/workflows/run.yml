name: auto-download-bq

on:
  schedule:
    - cron: "55 * * * *"   # UTC 기준 매시 55분 (KST도 '분'은 55분)
  workflow_dispatch:

# 같은 브랜치 기준으로만 동시성 제어
concurrency:
  group: auto-download-bq-${{ github.ref }}
  cancel-in-progress: false  # 수동/스케줄이 겹쳐도 이전 실행을 취소하지 않음

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 90      # 다운로드 지연/로그인/업로드까지 여유 있게
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Setup Chrome
        uses: browser-actions/setup-chrome@v1

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Restore GCP creds file
        env:
          SERVICE_ACCOUNT_JSON_B64: ${{ secrets.SERVICE_ACCOUNT_JSON_B64 }}
        run: |
          echo "$SERVICE_ACCOUNT_JSON_B64" | base64 -d > bigquery-credentials.json

      - name: Run script
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/bigquery-credentials.json
          LOGIN_ID: ${{ secrets.LOGIN_ID }}
          LOGIN_PW: ${{ secrets.LOGIN_PW }}
          GCP_PROJECT: ${{ secrets.GCP_PROJECT }}
          BQ_DATASET: ${{ secrets/BQ_DATASET }}
          BQ_TABLE: ${{ secrets/BQ_TABLE }}
        run: python auto_download_headless_log.py

      # 실패/취소 시에도 로그/산출물 보존
      - name: Upload logs/artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-artifacts
          path: |
            log.txt
            downloads/**
            *.png
            *.jpg
